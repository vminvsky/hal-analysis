
appworld_test_challenge win rate:
+-----------------------------------------+--------------------+--------------------+----------------+----------+-----------------+--------------------+
|            model_name_short             |   win_rate_mean    |    win_rate_std    | win_rate_count | wins_sum | comparisons_sum |  overall_win_rate  |
+-----------------------------------------+--------------------+--------------------+----------------+----------+-----------------+--------------------+
| deepseek-ai/deepseek-coder-33b-instruct |        0.0         |        0.0         |       3        |    0     |        9        |        0.0         |
|         gpt-4-turbo-2024-04-09          |        0.5         | 0.3333333333333333 |       4        |    6     |       10        |        0.6         |
|            gpt-4o-2024-05-13            |        1.0         |        0.0         |       4        |    10    |       10        |        1.0         |
|     meta-llama/Llama-3-70b-chat-hf      | 0.3333333333333333 |        0.0         |       3        |    3     |        9        | 0.3333333333333333 |
+-----------------------------------------+--------------------+--------------------+----------------+----------+-----------------+--------------------+


appworld_test_normal win rate:
+-----------------------------------------+--------------------+--------------------+----------------+----------+-----------------+--------------------+
|            model_name_short             |   win_rate_mean    |    win_rate_std    | win_rate_count | wins_sum | comparisons_sum |  overall_win_rate  |
+-----------------------------------------+--------------------+--------------------+----------------+----------+-----------------+--------------------+
| deepseek-ai/deepseek-coder-33b-instruct |        0.0         |        0.0         |       3        |    0     |        9        |        0.0         |
|         gpt-4-turbo-2024-04-09          |        0.5         | 0.3333333333333333 |       4        |    6     |       10        |        0.6         |
|            gpt-4o-2024-05-13            |        1.0         |        0.0         |       4        |    10    |       10        |        1.0         |
|     meta-llama/Llama-3-70b-chat-hf      | 0.3333333333333333 |        0.0         |       3        |    3     |        9        | 0.3333333333333333 |
+-----------------------------------------+--------------------+--------------------+----------------+----------+-----------------+--------------------+


corebench_easy win rate:
+------------------------+---------------+--------------+----------------+----------+-----------------+------------------+
|    model_name_short    | win_rate_mean | win_rate_std | win_rate_count | wins_sum | comparisons_sum | overall_win_rate |
+------------------------+---------------+--------------+----------------+----------+-----------------+------------------+
|   gpt-4o-2024-05-13    |      1.0      |     0.0      |       2        |    2     |        2        |       1.0        |
| gpt-4o-mini-2024-07-18 |      0.0      |     0.0      |       2        |    0     |        2        |       0.0        |
+------------------------+---------------+--------------+----------------+----------+-----------------+------------------+


corebench_hard win rate:
+------------------------------+---------------+--------------------+----------------+----------+-----------------+------------------+
|       model_name_short       | win_rate_mean |    win_rate_std    | win_rate_count | wins_sum | comparisons_sum | overall_win_rate |
+------------------------------+---------------+--------------------+----------------+----------+-----------------+------------------+
| claude-3.5-sonnet-2024-10-22 |      1.0      |        nan         |       1        |    4     |        4        |       1.0        |
|      gpt-4o-2024-05-13       |     0.625     | 0.5303300858899106 |       2        |    2     |        5        |       0.4        |
|    gpt-4o-mini-2024-07-18    |      0.0      |        0.0         |       2        |    0     |        5        |       0.0        |
|        o1-2024-12-17         |     0.75      |        nan         |       1        |    3     |        4        |       0.75       |
|      o1-mini-2024-09-12      |      0.5      |        nan         |       1        |    2     |        4        |       0.5        |
+------------------------------+---------------+--------------------+----------------+----------+-----------------+------------------+


corebench_medium win rate:
+------------------------+---------------+--------------+----------------+----------+-----------------+------------------+
|    model_name_short    | win_rate_mean | win_rate_std | win_rate_count | wins_sum | comparisons_sum | overall_win_rate |
+------------------------+---------------+--------------+----------------+----------+-----------------+------------------+
|   gpt-4o-2024-05-13    |      1.0      |     0.0      |       2        |    2     |        2        |       1.0        |
| gpt-4o-mini-2024-07-18 |      0.0      |     0.0      |       2        |    0     |        2        |       0.0        |
+------------------------+---------------+--------------+----------------+----------+-----------------+------------------+


inspect_evals/agentharm win rate:
+------------------------------------+--------------------+--------------+----------------+----------+-----------------+--------------------+
|          model_name_short          |   win_rate_mean    | win_rate_std | win_rate_count | wins_sum | comparisons_sum |  overall_win_rate  |
+------------------------------------+--------------------+--------------+----------------+----------+-----------------+--------------------+
| Meta-Llama-3.1-405B-Instruct-Turbo | 0.1666666666666666 |     nan      |       1        |    1     |        6        | 0.1666666666666666 |
|     claude-3-5-sonnet-20241022     | 0.3333333333333333 |     nan      |       1        |    2     |        6        | 0.3333333333333333 |
|         gpt-4o-2024-11-20          | 0.8333333333333334 |     nan      |       1        |    5     |        6        | 0.8333333333333334 |
|       gpt-4o-mini-2024-07-18       |        1.0         |     nan      |       1        |    6     |        6        |        1.0         |
|           o1-2024-12-17            |        0.5         |     nan      |       1        |    3     |        6        |        0.5         |
|         o1-mini-2024-09-12         | 0.6666666666666666 |     nan      |       1        |    4     |        6        | 0.6666666666666666 |
|       o1-preview-2024-09-12        |        0.0         |     nan      |       1        |    0     |        6        |        0.0         |
+------------------------------------+--------------------+--------------+----------------+----------+-----------------+--------------------+


inspect_evals/agentharm_benign win rate:
+------------------------------------+---------------+--------------+----------------+----------+-----------------+------------------+
|          model_name_short          | win_rate_mean | win_rate_std | win_rate_count | wins_sum | comparisons_sum | overall_win_rate |
+------------------------------------+---------------+--------------+----------------+----------+-----------------+------------------+
| Meta-Llama-3.1-405B-Instruct-Turbo |      0.0      |     nan      |       1        |    0     |        5        |       0.0        |
|     claude-3-5-sonnet-20241022     |      0.6      |     nan      |       1        |    3     |        5        |       0.6        |
|         gpt-4o-2024-11-20          |      1.0      |     nan      |       1        |    5     |        5        |       1.0        |
|       gpt-4o-mini-2024-07-18       |      0.4      |     nan      |       1        |    2     |        5        |       0.4        |
|           o1-2024-12-17            |      0.8      |     nan      |       1        |    4     |        5        |       0.8        |
|         o1-mini-2024-09-12         |      0.2      |     nan      |       1        |    1     |        5        |       0.2        |
+------------------------------------+---------------+--------------+----------------+----------+-----------------+------------------+


inspect_evals/cybench win rate:
+------------------------------------+--------------------+--------------+----------------+----------+-----------------+--------------------+
|          model_name_short          |   win_rate_mean    | win_rate_std | win_rate_count | wins_sum | comparisons_sum |  overall_win_rate  |
+------------------------------------+--------------------+--------------+----------------+----------+-----------------+--------------------+
| Meta-Llama-3.1-405B-Instruct-Turbo |        0.0         |     nan      |       1        |    0     |        6        |        0.0         |
|     claude-3-5-sonnet-20241022     | 0.6666666666666666 |     nan      |       1        |    4     |        6        | 0.6666666666666666 |
|     claude-3-7-sonnet-20250219     |        nan         |     nan      |       0        |    0     |        0        |        nan         |
|         gpt-4o-2024-11-20          | 0.3333333333333333 |     nan      |       1        |    2     |        6        | 0.3333333333333333 |
|       gpt-4o-mini-2024-07-18       | 0.1666666666666666 |     nan      |       1        |    1     |        6        | 0.1666666666666666 |
|         o1-mini-2024-09-12         | 0.3333333333333333 |     nan      |       1        |    2     |        6        | 0.3333333333333333 |
|       o1-preview-2024-09-12        | 0.6666666666666666 |     nan      |       1        |    4     |        6        | 0.6666666666666666 |
|         o3-mini-2025-01-14         |        1.0         |     nan      |       1        |    6     |        6        |        1.0         |
+------------------------------------+--------------------+--------------+----------------+----------+-----------------+--------------------+


inspect_evals/gaia win rate:
+------------------------------------+--------------------+--------------+----------------+----------+-----------------+--------------------+
|          model_name_short          |   win_rate_mean    | win_rate_std | win_rate_count | wins_sum | comparisons_sum |  overall_win_rate  |
+------------------------------------+--------------------+--------------+----------------+----------+-----------------+--------------------+
| Meta-Llama-3.1-405B-Instruct-Turbo |        0.0         |     nan      |       1        |    0     |        7        |        0.0         |
|     claude-3-5-sonnet-20241022     |        1.0         |     nan      |       1        |    7     |        7        |        1.0         |
|     claude-3-7-sonnet-20250219     | 0.7142857142857143 |     nan      |       1        |    5     |        7        | 0.7142857142857143 |
|         gpt-4o-2024-11-20          | 0.2857142857142857 |     nan      |       1        |    2     |        7        | 0.2857142857142857 |
|       gpt-4o-mini-2024-07-18       | 0.1428571428571428 |     nan      |       1        |    1     |        7        | 0.1428571428571428 |
|         o1-mini-2024-09-12         | 0.4285714285714285 |     nan      |       1        |    3     |        7        | 0.4285714285714285 |
|       o1-preview-2024-09-12        | 0.7142857142857143 |     nan      |       1        |    5     |        7        | 0.7142857142857143 |
|      o3-mini-2025-01-31 med.       | 0.5714285714285714 |     nan      |       1        |    4     |        7        | 0.5714285714285714 |
+------------------------------------+--------------------+--------------+----------------+----------+-----------------+--------------------+


swebench_verified win rate:
+----------------------------+---------------+--------------+----------------+----------+-----------------+------------------+
|      model_name_short      | win_rate_mean | win_rate_std | win_rate_count | wins_sum | comparisons_sum | overall_win_rate |
+----------------------------+---------------+--------------+----------------+----------+-----------------+------------------+
| claude-3-5-sonnet-20241022 |      1.0      |     nan      |       1        |    1     |        1        |       1.0        |
|     gpt-4o-2024-08-06      |      0.0      |     nan      |       1        |    0     |        1        |       0.0        |
|     o1-mini-2024-09-12     |      nan      |     nan      |       0        |    0     |        0        |       nan        |
+----------------------------+---------------+--------------+----------------+----------+-----------------+------------------+


swebench_verified_mini win rate:
+----------------------------+---------------+--------------+----------------+----------+-----------------+------------------+
|      model_name_short      | win_rate_mean | win_rate_std | win_rate_count | wins_sum | comparisons_sum | overall_win_rate |
+----------------------------+---------------+--------------+----------------+----------+-----------------+------------------+
| claude-3-5-sonnet-20241022 |      1.0      |     nan      |       1        |    2     |        2        |       1.0        |
|     gpt-4o-2024-08-06      |      0.5      |     nan      |       1        |    1     |        2        |       0.5        |
|   gpt-4o-mini-2024-07-18   |      0.0      |     0.0      |       2        |    0     |        3        |       0.0        |
|     o1-mini-2024-09-12     |      1.0      |     nan      |       1        |    1     |        1        |       1.0        |
|     o3-mini-2025-01-31     |      nan      |     nan      |       0        |    0     |        0        |       nan        |
+----------------------------+---------------+--------------+----------------+----------+-----------------+------------------+


taubench_airline win rate:
+----------------------------+---------------+--------------+----------------+----------+-----------------+------------------+
|      model_name_short      | win_rate_mean | win_rate_std | win_rate_count | wins_sum | comparisons_sum | overall_win_rate |
+----------------------------+---------------+--------------+----------------+----------+-----------------+------------------+
| claude-3-5-sonnet-20241022 |      0.4      |     nan      |       1        |    2     |        5        |       0.4        |
| claude-3-7-sonnet-20250219 |      0.8      |     nan      |       1        |    4     |        5        |       0.8        |
|     gpt-4o-2024-11-20      |      0.4      |     nan      |       1        |    2     |        5        |       0.4        |
|   gpt-4o-mini-2024-07-18   |      0.0      |     nan      |       1        |    0     |        5        |       0.0        |
|     o1-2024-12-17 med.     |      1.0      |     nan      |       1        |    5     |        5        |       1.0        |
|  o3-mini-2025-01-31 med.   |      0.2      |     nan      |       1        |    1     |        5        |       0.2        |
+----------------------------+---------------+--------------+----------------+----------+-----------------+------------------+


taubench_retail win rate:
+----------------------------+---------------+--------------+----------------+----------+-----------------+------------------+
|      model_name_short      | win_rate_mean | win_rate_std | win_rate_count | wins_sum | comparisons_sum | overall_win_rate |
+----------------------------+---------------+--------------+----------------+----------+-----------------+------------------+
| claude-3-5-sonnet-20241022 |      0.6      |     nan      |       1        |    3     |        5        |       0.6        |
| claude-3-7-sonnet-20250219 |      1.0      |     nan      |       1        |    5     |        5        |       1.0        |
|     gpt-4o-2024-11-20      |      0.4      |     nan      |       1        |    2     |        5        |       0.4        |
|   gpt-4o-mini-2024-07-18   |      0.0      |     nan      |       1        |    0     |        5        |       0.0        |
|     o1-2024-12-17 med.     |      0.8      |     nan      |       1        |    4     |        5        |       0.8        |
|  o3-mini-2025-01-31 med.   |      0.2      |     nan      |       1        |    1     |        5        |       0.2        |
+----------------------------+---------------+--------------+----------------+----------+-----------------+------------------+


usaco win rate:
+-----------------------------------+---------------+--------------------+----------------+----------+-----------------+--------------------+
|         model_name_short          | win_rate_mean |    win_rate_std    | win_rate_count | wins_sum | comparisons_sum |  overall_win_rate  |
+-----------------------------------+---------------+--------------------+----------------+----------+-----------------+--------------------+
| Meta-Llama-3.3-70B-Instruct-Turbo |      0.0      |        nan         |       1        |    0     |        2        |        0.0         |
|     claude-3-5-haiku-20241022     |      0.5      |        nan         |       1        |    1     |        2        |        0.5         |
|    claude-3-5-sonnet-20241022     |      1.0      |        nan         |       1        |    2     |        2        |        1.0         |
|    claude-3-7-sonnet-20250219     |     0.25      | 0.3535533905932738 |       2        |    1     |        3        | 0.3333333333333333 |
|         gpt-4o-2024-05-13         |      1.0      |        0.0         |       5        |    5     |        5        |        1.0         |
|      gpt-4o-mini-2024-07-18       |      0.0      |        0.0         |       5        |    0     |        5        |        0.0         |
|        o1-mini-2024-09-12         |      0.0      |        nan         |       1        |    0     |        2        |        0.0         |
|        o3-mini-2025-01-31         |      1.0      |        nan         |       1        |    1     |        1        |        1.0         |
|      o3-mini-2025-01-31 med.      |      1.0      |        nan         |       1        |    2     |        2        |        1.0         |
+-----------------------------------+---------------+--------------------+----------------+----------+-----------------+--------------------+

